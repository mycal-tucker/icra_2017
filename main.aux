\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{IEEEtran}
\citation{g3}
\citation{dcg}
\citation{adcg2016}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An illustration of learning and grounding an unknown object. The robot (a) knows what a sphere is, (b) learns what a cone is, (c) sees a cone again, (d) moves towards the cone that is a known object from now on.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intro_pic}{{1}{1}{An illustration of learning and grounding an unknown object. The robot (a) knows what a sphere is, (b) learns what a cone is, (c) sees a cone again, (d) moves towards the cone that is a known object from now on.\relax }{figure.caption.1}{}}
\newlabel{fig:intro_pic@cref}{{[figure][1][]1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Grounding Natural Language Instructions}{1}{section.2}}
\newlabel{sec:background}{{II}{1}{Grounding Natural Language Instructions}{section.2}{}}
\newlabel{sec:background@cref}{{[section][2][]II}{1}}
\citation{dcg}
\newlabel{eq:max_ground_prob}{{1}{2}{Grounding Natural Language Instructions}{equation.2.1}{}}
\newlabel{eq:max_ground_prob@cref}{{[equation][1][]1}{2}}
\newlabel{eq:dcg_factored1}{{2}{2}{Grounding Natural Language Instructions}{equation.2.2}{}}
\newlabel{eq:dcg_factored1@cref}{{[equation][2][]2}{2}}
\newlabel{fig:parse_tree}{{2a}{2}{The parse tree for the command ``move to the cube''\relax }{figure.caption.2}{}}
\newlabel{fig:parse_tree@cref}{{[subfigure][1][2]2a}{2}}
\newlabel{sub@fig:parse_tree}{{a}{2}{The parse tree for the command ``move to the cube''\relax }{figure.caption.2}{}}
\newlabel{sub@fig:parse_tree@cref}{{[subfigure][1][2]2a}{2}}
\newlabel{fig:dcg_plates}{{2b}{2}{The DCG graphical model for the parse tree in Fig.~\ref {fig:parse_tree}\relax }{figure.caption.2}{}}
\newlabel{fig:dcg_plates@cref}{{[subfigure][2][2]2b}{2}}
\newlabel{sub@fig:dcg_plates}{{b}{2}{The DCG graphical model for the parse tree in Fig.~\ref {fig:parse_tree}\relax }{figure.caption.2}{}}
\newlabel{sub@fig:dcg_plates@cref}{{[subfigure][2][2]2b}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An illustration of a parse tree and the corresponding DCG model where the graph topology of (b) is derived from the structure in (a). In the DCG model, the gray nodes are the observed variables (i.e., the correspondence variables), the white nodes in the plates are the unobserved variables (i.e., the grounding symbols), and the black nodes denote the factors (i.e., representing the conditional relationship between the variables)\relax }}{2}{figure.caption.2}}
\newlabel{eq:llm1}{{3}{2}{Grounding Natural Language Instructions}{equation.2.3}{}}
\newlabel{eq:llm1@cref}{{[equation][3][]3}{2}}
\citation{liu1989}
\citation{grimmett2013}
\newlabel{eq:llm2}{{4}{3}{Grounding Natural Language Instructions}{equation.2.4}{}}
\newlabel{eq:llm2@cref}{{[equation][4][]4}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Probabilistic Model for Grounding Unknown Symbols}{3}{section.3}}
\newlabel{sec:technical}{{III}{3}{Probabilistic Model for Grounding Unknown Symbols}{section.3}{}}
\newlabel{sec:technical@cref}{{[section][3][]III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Grounding Unknown Phrases or Objects}{3}{subsection.3.1}}
\newlabel{eq:dcg_upup_llm1}{{5}{3}{Grounding Unknown Phrases or Objects}{equation.3.5}{}}
\newlabel{eq:dcg_upup_llm1@cref}{{[equation][5][]5}{3}}
\newlabel{eq:dcg_upup_llm2}{{6}{3}{Grounding Unknown Phrases or Objects}{equation.3.6}{}}
\newlabel{eq:dcg_upup_llm2@cref}{{[equation][6][]6}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Grounding Hypothetical Objects Outside the Field of View}{3}{subsection.3.2}}
\newlabel{fig:dcg-upup}{{3a}{4}{The DCG-UPUP model\relax }{figure.caption.3}{}}
\newlabel{fig:dcg-upup@cref}{{[subfigure][1][3]3a}{4}}
\newlabel{sub@fig:dcg-upup}{{a}{4}{The DCG-UPUP model\relax }{figure.caption.3}{}}
\newlabel{sub@fig:dcg-upup@cref}{{[subfigure][1][3]3a}{4}}
\newlabel{fig:dcg-upup-away}{{3b}{4}{The DCG-UPUP-Away model\relax }{figure.caption.3}{}}
\newlabel{fig:dcg-upup-away@cref}{{[subfigure][2][3]3b}{4}}
\newlabel{sub@fig:dcg-upup-away}{{b}{4}{The DCG-UPUP-Away model\relax }{figure.caption.3}{}}
\newlabel{sub@fig:dcg-upup-away@cref}{{[subfigure][2][3]3b}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The graphical models instantiated for the command ``{move to the cube}". (a) The unknown groundings are explicitly represented and the grounding variables are assumed to be perceived. (b) The unknown perceived, known perceived, known hypothetical, and unknown hypothetical groundings are explicitly represented (separated by dashed lines).\relax }}{4}{figure.caption.3}}
\newlabel{eq:dcg_upup_away_llm1}{{7}{4}{Grounding Hypothetical Objects Outside the Field of View}{equation.3.7}{}}
\newlabel{eq:dcg_upup_away_llm1@cref}{{[equation][7][]7}{4}}
\newlabel{eq:dcg_upup_away_factor}{{8}{4}{Grounding Hypothetical Objects Outside the Field of View}{equation.3.8}{}}
\newlabel{eq:dcg_upup_away_factor@cref}{{[equation][8][]8}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Online Learning}{4}{section.4}}
\newlabel{sec:implementation}{{IV}{4}{Online Learning}{section.4}{}}
\newlabel{sec:implementation@cref}{{[section][4][]IV}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Exploration to Find an Unknown Object}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Incremental Unsupervised Learning}{4}{subsection.4.2}}
\citation{zitnick2014edge}
\citation{bosch2007image}
\citation{vedaldi2010vlfeat}
\citation{fan2008liblinear}
\@writefile{toc}{\contentsline {section}{\numberline {V}Evaluation}{5}{section.5}}
\newlabel{sec:evaluation}{{V}{5}{Evaluation}{section.5}{}}
\newlabel{sec:evaluation@cref}{{[section][5][]V}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-A}Corpus}{5}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-B}Testing/Training Setup}{5}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {V-C}Perception Pipeline}{5}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces A simulated world with a highlighted object presented on Amazon Mechanical Turk, labeled by a user as ``Move to the red fire hydrant.''\relax }}{5}{figure.caption.4}}
\newlabel{fig:amt}{{4}{5}{A simulated world with a highlighted object presented on Amazon Mechanical Turk, labeled by a user as ``Move to the red fire hydrant.''\relax }{figure.caption.4}{}}
\newlabel{fig:amt@cref}{{[figure][4][]4}{5}}
\citation{calli2015ycb}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Results}{6}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-A}Grounding Accuracy}{6}{subsection.6.1}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces The summary of results showing the fraction of accurate, inaccurate, and uninformed groundings of $100$ commands.\relax }}{6}{table.caption.6}}
\newlabel{tab:resultDCG}{{I}{6}{The summary of results showing the fraction of accurate, inaccurate, and uninformed groundings of $100$ commands.\relax }{table.caption.6}{}}
\newlabel{tab:resultDCG@cref}{{[table][1][]I}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-B}Learned Symbols}{6}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-C}Physical Demonstration}{6}{subsection.6.3}}
\citation{g3}
\citation{dcg}
\citation{citeLangNoisySensor}
\citation{outside1}
\citation{whichOne}
\citation{kids1}
\citation{perspective1}
\citation{perspective2}
\citation{clarifyingCommands}
\citation{interaction1}
\citation{interaction2}
\newlabel{fig:g_acc}{{5a}{7}{The overall grounding accuracy rate over various iterations.\relax }{figure.caption.5}{}}
\newlabel{fig:g_acc@cref}{{[subfigure][1][5]5a}{7}}
\newlabel{sub@fig:g_acc}{{a}{7}{The overall grounding accuracy rate over various iterations.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:g_acc@cref}{{[subfigure][1][5]5a}{7}}
\newlabel{fig:g_acc_split}{{5b}{7}{The mean percentage of known, learned, and unknown symbols during the simulations.\relax }{figure.caption.5}{}}
\newlabel{fig:g_acc_split@cref}{{[subfigure][2][5]5b}{7}}
\newlabel{sub@fig:g_acc_split}{{b}{7}{The mean percentage of known, learned, and unknown symbols during the simulations.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:g_acc_split@cref}{{[subfigure][2][5]5b}{7}}
\newlabel{fig:symbols}{{5c}{7}{The number of new symbols acquired during the simulations.\relax }{figure.caption.5}{}}
\newlabel{fig:symbols@cref}{{[subfigure][3][5]5c}{7}}
\newlabel{sub@fig:symbols}{{c}{7}{The number of new symbols acquired during the simulations.\relax }{figure.caption.5}{}}
\newlabel{sub@fig:symbols@cref}{{[subfigure][3][5]5c}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The DCG-UPUP-Away model was used to ground $30$ trials, each of which included $10$ iterations (i.e., a specific pair of command and world model).\relax }}{7}{figure.caption.5}}
\newlabel{fig:exp1}{{6a}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp1@cref}{{[subfigure][1][6]6a}{7}}
\newlabel{sub@fig:exp1}{{a}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp1@cref}{{[subfigure][1][6]6a}{7}}
\newlabel{fig:exp2}{{6b}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp2@cref}{{[subfigure][2][6]6b}{7}}
\newlabel{sub@fig:exp2}{{b}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp2@cref}{{[subfigure][2][6]6b}{7}}
\newlabel{fig:exp3}{{6c}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp3@cref}{{[subfigure][3][6]6c}{7}}
\newlabel{sub@fig:exp3}{{c}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp3@cref}{{[subfigure][3][6]6c}{7}}
\newlabel{fig:exp4}{{6d}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp4@cref}{{[subfigure][4][6]6d}{7}}
\newlabel{sub@fig:exp4}{{d}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp4@cref}{{[subfigure][4][6]6d}{7}}
\newlabel{fig:exp5}{{6e}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp5@cref}{{[subfigure][5][6]6e}{7}}
\newlabel{sub@fig:exp5}{{e}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp5@cref}{{[subfigure][5][6]6e}{7}}
\newlabel{fig:exp6}{{6f}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp6@cref}{{[subfigure][6][6]6f}{7}}
\newlabel{sub@fig:exp6}{{f}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp6@cref}{{[subfigure][6][6]6f}{7}}
\newlabel{fig:exp7}{{6g}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp7@cref}{{[subfigure][7][6]6g}{7}}
\newlabel{sub@fig:exp7}{{g}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp7@cref}{{[subfigure][7][6]6g}{7}}
\newlabel{fig:exp8}{{6h}{7}{\relax }{figure.caption.7}{}}
\newlabel{fig:exp8@cref}{{[subfigure][8][6]6h}{7}}
\newlabel{sub@fig:exp8}{{h}{7}{\relax }{figure.caption.7}{}}
\newlabel{sub@fig:exp8@cref}{{[subfigure][8][6]6h}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An illustration of grounding to an unknown hypothetical object. The TurtleBot initially knew all objects in the world other than fruits. The robot was given a command as ``move to the fruits". (a) First, it did not see an unknown object in its perceived world so it created a hypothetical unknown object, (b,c,d,e,f,) it explored the world by rotating at its current location until it perceives an unknown object, (g) it perceived an unknown object and grounded to it, (h) it drove to the fruits.\relax }}{7}{figure.caption.7}}
\newlabel{fig:crate}{{6}{7}{An illustration of grounding to an unknown hypothetical object. The TurtleBot initially knew all objects in the world other than fruits. The robot was given a command as ``move to the fruits". (a) First, it did not see an unknown object in its perceived world so it created a hypothetical unknown object, (b,c,d,e,f,) it explored the world by rotating at its current location until it perceives an unknown object, (g) it perceived an unknown object and grounded to it, (h) it drove to the fruits.\relax }{figure.caption.7}{}}
\newlabel{fig:crate@cref}{{[figure][6][]6}{7}}
\newlabel{fig:exp_new_1}{{7a}{7}{t= 0 sec.\relax }{figure.caption.8}{}}
\newlabel{fig:exp_new_1@cref}{{[subfigure][1][7]7a}{7}}
\newlabel{sub@fig:exp_new_1}{{a}{7}{t= 0 sec.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:exp_new_1@cref}{{[subfigure][1][7]7a}{7}}
\newlabel{fig:exp_new_2}{{7b}{7}{t= 45 sec.\relax }{figure.caption.8}{}}
\newlabel{fig:exp_new_2@cref}{{[subfigure][2][7]7b}{7}}
\newlabel{sub@fig:exp_new_2}{{b}{7}{t= 45 sec.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:exp_new_2@cref}{{[subfigure][2][7]7b}{7}}
\newlabel{fig:exp_new_3}{{7c}{7}{t= 50 sec.\relax }{figure.caption.8}{}}
\newlabel{fig:exp_new_3@cref}{{[subfigure][3][7]7c}{7}}
\newlabel{sub@fig:exp_new_3}{{c}{7}{t= 50 sec.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:exp_new_3@cref}{{[subfigure][3][7]7c}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces An illustration of learning new symbol. The TurtleBot initially did not know what a box is, a command was given as ``move to the box". (a) Due to the presence of an unknown object in its perceived world, it grounded the unknown phrase ``the box" to the unknown object, (b,c) it drove to the box.\relax }}{7}{figure.caption.8}}
\newlabel{fig:cone}{{7}{7}{An illustration of learning new symbol. The TurtleBot initially did not know what a box is, a command was given as ``move to the box". (a) Due to the presence of an unknown object in its perceived world, it grounded the unknown phrase ``the box" to the unknown object, (b,c) it drove to the box.\relax }{figure.caption.8}{}}
\newlabel{fig:cone@cref}{{[figure][7][]7}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {VI-D}Limitations}{7}{subsection.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Related Work}{7}{section.7}}
\newlabel{sec:related}{{VII}{7}{Related Work}{section.7}{}}
\newlabel{sec:related@cref}{{[section][7][]VII}{7}}
\citation{langlearn1}
\citation{langlearn2}
\citation{formal1}
\citation{formal2}
\citation{mooneypivot}
\citation{langlearn3}
\citation{langlearn4}
\citation{citeLangNoisySensor}
\citation{learningSemanticMaps}
\citation{outside1}
\bibdata{ref}
\bibcite{g3}{1}
\bibcite{dcg}{2}
\bibcite{adcg2016}{3}
\bibcite{liu1989}{4}
\bibcite{grimmett2013}{5}
\bibcite{zitnick2014edge}{6}
\bibcite{bosch2007image}{7}
\bibcite{vedaldi2010vlfeat}{8}
\bibcite{fan2008liblinear}{9}
\bibcite{calli2015ycb}{10}
\bibcite{citeLangNoisySensor}{11}
\bibcite{outside1}{12}
\bibcite{whichOne}{13}
\bibcite{kids1}{14}
\bibcite{perspective1}{15}
\bibcite{perspective2}{16}
\bibcite{clarifyingCommands}{17}
\bibcite{interaction1}{18}
\bibcite{interaction2}{19}
\bibcite{langlearn1}{20}
\bibcite{langlearn2}{21}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Conclusion}{8}{section.8}}
\newlabel{sec:conclusion}{{VIII}{8}{Conclusion}{section.8}{}}
\newlabel{sec:conclusion@cref}{{[section][8][]VIII}{8}}
\@writefile{toc}{\contentsline {section}{References}{8}{section*.9}}
\bibcite{formal1}{22}
\bibcite{formal2}{23}
\bibcite{mooneypivot}{24}
\bibcite{langlearn3}{25}
\bibcite{langlearn4}{26}
\bibcite{learningSemanticMaps}{27}
